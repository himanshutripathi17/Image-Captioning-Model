# Image-Captioning-Model
This is an AI-driven model which generates a caption for the input image provided to the model.


Developed an automated image captioning system using the Flickr8k dataset, integrating Convolutional Neural Networks (CNNs) and Long Short-Term Memory (LSTM) networks. Utilized a pre-trained VGG16 model for visual feature extraction and an LSTM-based architecture for sequential text generation. The model effectively interprets image semantics and generates coherent textual descriptions by combining spatial and temporal learning. Evaluated performance using BLEU scores and fine-tuned the model through iterative training and hyperparameter optimization. This project demonstrates the potential of CNN-LSTM integration for context-aware captioning, with applications in accessibility tools, automated content generation, and intelligent image retrieval.

Note: Some .pkl files and a few files were not uploaded to the repository due to their large size.
